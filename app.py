import streamlit as st
from openai import OpenAI
import os
from typing import List, Dict, Any
from dotenv import load_dotenv

# Import our enhanced database and models
from database import DatabaseManager
from models import Character, MessageRole

# Import audio processing utilities
from audio_utils import audio_manager, AudioUI

try:
    from audiorecorder import audiorecorder

    AUDIO_RECORDER_AVAILABLE = True
except ImportError:
    AUDIO_RECORDER_AVAILABLE = False

load_dotenv()


class AIRolePlayApp:
    def __init__(self):
        self.db = DatabaseManager()
        self.init_openai()
        self.init_session_state()
        self.init_audio_cleanup()

    def init_openai(self):
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            st.error("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®OPENAI_API_KEY")
            st.stop()
        self.client = OpenAI(api_key=api_key)

    def init_session_state(self):
        if "messages" not in st.session_state:
            st.session_state.messages = []
        if "selected_character" not in st.session_state:
            st.session_state.selected_character = None
        if "current_conversation_id" not in st.session_state:
            st.session_state.current_conversation_id = None

    def init_audio_cleanup(self):
        """Initialize audio file cleanup on app start"""
        try:
            # Clean up old audio files (older than 24 hours)
            audio_manager.cleanup_old_files(max_age_hours=24)
        except Exception:
            # Silently handle cleanup errors
            pass

    def get_character_prompt(self, character: Character) -> str:
        """Generate system prompt from character template"""
        # Use the character's prompt_template directly
        return character.prompt_template

    def generate_response(self, messages: List[Dict], character: Character) -> str:
        try:
            system_prompt = self.get_character_prompt(character)

            formatted_messages = [{"role": "system", "content": system_prompt}]
            formatted_messages.extend(messages)

            response = self.client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
                messages=formatted_messages,
                max_tokens=500,
                temperature=0.8,
            )

            return response.choices[0].message.content

        except Exception as e:
            return f"æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›åº”ã€‚é”™è¯¯ï¼š{str(e)}"

    def render_sidebar(self):
        with st.sidebar:
            st.title("ğŸ­ è§’è‰²é€‰æ‹©")

            characters = self.db.get_all_characters()

            if not characters:
                st.warning(
                    "æ²¡æœ‰æ‰¾åˆ°è§’è‰²ã€‚è¯·è¿è¡Œ `python init_database.py` åˆå§‹åŒ–æ•°æ®åº“ã€‚"
                )
                return

            character_options = {
                f"{char.avatar_emoji} {char.name}": char for char in characters
            }

            selected_display_name = st.selectbox(
                "é€‰æ‹©ä¸€ä¸ªè§’è‰²å¼€å§‹å¯¹è¯", list(character_options.keys()), index=0
            )

            if selected_display_name:
                selected_character = character_options[selected_display_name]

                # Check if character changed
                if (
                    st.session_state.selected_character is None
                    or st.session_state.selected_character.id != selected_character.id
                ):
                    st.session_state.selected_character = selected_character
                    st.session_state.messages = []
                    st.session_state.current_conversation_id = None

                st.markdown("---")

                # Display character info
                st.markdown(
                    f"### {selected_character.avatar_emoji} {selected_character.name}"
                )
                st.markdown(f"**{selected_character.title}**")

                # Display personality traits
                if selected_character.personality:
                    st.markdown("**æ€§æ ¼ç‰¹å¾:**")
                    for trait in selected_character.personality:
                        st.markdown(f"â€¢ {trait}")

                # Display skills
                if selected_character.skills:
                    st.markdown("**æŠ€èƒ½:**")
                    skills_text = ", ".join(selected_character.skills[:3])
                    if len(selected_character.skills) > 3:
                        skills_text += f" ç­‰{len(selected_character.skills)}é¡¹æŠ€èƒ½"
                    st.markdown(f"*{skills_text}*")

                st.markdown("---")

                # Action buttons
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", type="secondary"):
                        st.session_state.messages = []
                        st.session_state.current_conversation_id = None
                        st.rerun()

                with col2:
                    if st.button("ğŸ’¾ ä¿å­˜å¯¹è¯"):
                        self.save_current_conversation()
                        st.success("å¯¹è¯å·²ä¿å­˜!")

    def save_current_conversation(self):
        """Save current conversation to database"""
        if not st.session_state.selected_character or not st.session_state.messages:
            return

        character = st.session_state.selected_character

        # Create conversation if not exists
        if not st.session_state.current_conversation_id:
            # Generate title from first user message
            title = "æ–°å¯¹è¯"
            if st.session_state.messages:
                first_user_msg = next(
                    (msg for msg in st.session_state.messages if msg["role"] == "user"),
                    None,
                )
                if first_user_msg:
                    title = first_user_msg["content"][:30] + (
                        "..." if len(first_user_msg["content"]) > 30 else ""
                    )

            conversation_id = self.db.create_conversation(character.id, title)
            st.session_state.current_conversation_id = conversation_id

        # Add messages to conversation
        for message in st.session_state.messages:
            # Check if message already exists (basic deduplication)
            metadata = message.get("metadata")
            self.db.add_message(
                conversation_id=st.session_state.current_conversation_id,
                role=message["role"],
                content=message["content"],
                metadata=metadata,
            )

    def render_chat(self):
        if not st.session_state.selected_character:
            st.info("è¯·åœ¨å·¦ä¾§é€‰æ‹©ä¸€ä¸ªè§’è‰²å¼€å§‹å¯¹è¯")
            return

        character = st.session_state.selected_character
        st.title(f"ğŸ’¬ ä¸ {character.avatar_emoji} {character.name} å¯¹è¯")

        # Display character description
        st.markdown(f"*{character.title}*")
        st.markdown("---")

        chat_container = st.container()

        with chat_container:
            for message in st.session_state.messages:
                role = message["role"]
                content = message["content"]
                metadata = message.get("metadata", {})

                if role == "user":
                    with st.chat_message("user"):
                        # Check if this is an audio message
                        if "audio" in metadata:
                            self.render_audio_message(metadata["audio"], content)
                        else:
                            st.markdown(content)
                elif role == "assistant":
                    with st.chat_message("assistant", avatar=character.avatar_emoji):
                        st.markdown(content)

        # Input section with both text and audio options
        self.render_input_section(character)

    def render_audio_message(self, audio_metadata: Dict[str, Any], content: str):
        """Render an audio message with playback controls"""
        st.markdown(
            f"ğŸ¤ **è¯­éŸ³æ¶ˆæ¯** ({audio_manager.format_duration(audio_metadata.get('duration', 0))})"
        )

        # Show transcription if available
        if content and content != "[éŸ³é¢‘æ¶ˆæ¯]":
            st.markdown(f"*è½¬å½•æ–‡æœ¬:* {content}")

        # Audio playback
        file_path = audio_metadata.get("file_path")
        if file_path and os.path.exists(file_path):
            with open(file_path, "rb") as audio_file:
                st.audio(audio_file.read(), format="audio/wav")

    def render_input_section(self, character: Character):
        """Render input section with text and audio options"""
        # Text input
        text_prompt = st.chat_input("è¾“å…¥ä½ çš„æ¶ˆæ¯...")

        # Audio recording section
        if AUDIO_RECORDER_AVAILABLE:
            st.markdown("### ğŸ¤ è¯­éŸ³å½•åˆ¶")

            # Check dependencies and show warnings
            dependencies_ok = AudioUI.show_dependencies_warning()

            if not dependencies_ok:
                st.info("è¯­éŸ³åŠŸèƒ½æš‚ä¸å¯ç”¨ï¼Œè¯·ä½¿ç”¨æ–‡æœ¬è¾“å…¥")
            else:
                # Check HTTPS requirement
                if not self._check_https_context():
                    AudioUI.show_error_message("https_required")
                    st.info("è¯·ä½¿ç”¨æ–‡æœ¬è¾“å…¥")
                else:
                    col1, col2 = st.columns([3, 1])

                    with col1:
                        try:
                            audio = audiorecorder("ç‚¹å‡»å½•åˆ¶", "ç‚¹å‡»åœæ­¢")
                        except Exception as e:
                            AudioUI.show_error_message("recording_failed", str(e))
                            audio = None

                    with col2:
                        if audio and len(audio) > 0:
                            # Validate audio before showing controls
                            is_valid, error_msg = audio_manager.validate_audio(audio)

                            if is_valid:
                                # Show audio info
                                duration = len(audio) / 1000.0
                                st.write(f"â±ï¸ {audio_manager.format_duration(duration)}")

                                # Preview audio
                                try:
                                    st.audio(audio.export().read(), format="audio/wav")
                                except Exception:
                                    st.warning("éŸ³é¢‘é¢„è§ˆä¸å¯ç”¨")

                                # Send audio button
                                if st.button("ğŸ“¤ å‘é€è¯­éŸ³", type="primary"):
                                    self.process_user_message(
                                        "[éŸ³é¢‘æ¶ˆæ¯]", audio, character
                                    )
                                    st.rerun()
                            else:
                                st.error(f"éŸ³é¢‘éªŒè¯å¤±è´¥: {error_msg}")

        else:
            st.warning(
                "âš ï¸ è¯­éŸ³å½•åˆ¶åŠŸèƒ½ä¸å¯ç”¨ã€‚è¯·å®‰è£…: pip install streamlit-audiorecorder"
            )

        # Process text input
        if text_prompt:
            self.process_user_message(text_prompt, None, character)

    def _check_https_context(self) -> bool:
        """Check if the app is running in HTTPS context for audio recording"""
        try:
            # In Streamlit Cloud or when served over HTTPS, this should work
            # This is a basic check - the actual audio recording will fail gracefully if not HTTPS
            return True  # Let the audiorecorder component handle the HTTPS requirement
        except Exception:
            return False

    def process_user_message(
        self, content: str, audio_segment=None, character: Character = None
    ):
        """Process user message (text or audio) and generate response"""
        message_data = {"role": "user", "content": content}

        # Handle audio message
        if audio_segment is not None:
            try:
                # Save audio file
                audio_metadata = audio_manager.save_audio(
                    audio_segment,
                    conversation_id=st.session_state.current_conversation_id,
                )

                if audio_metadata:
                    message_data["metadata"] = {"audio": audio_metadata}
                else:
                    st.error("éŸ³é¢‘å¤„ç†å¤±è´¥ï¼Œå°†ä½œä¸ºæ–‡æœ¬æ¶ˆæ¯å‘é€")

            except Exception as e:
                st.error(f"éŸ³é¢‘å¤„ç†é”™è¯¯: {str(e)}")

        # Add user message to session
        st.session_state.messages.append(message_data)

        # Display user message
        with st.chat_message("user"):
            if audio_segment is not None and message_data.get("metadata", {}).get(
                "audio"
            ):
                self.render_audio_message(message_data["metadata"]["audio"], content)
            else:
                st.markdown(content)

        # Generate assistant response
        if character:
            with st.chat_message("assistant", avatar=character.avatar_emoji):
                with st.spinner(f"{character.name}æ­£åœ¨æ€è€ƒ..."):
                    # For audio messages, use the content as text for AI processing
                    response = self.generate_response(
                        st.session_state.messages, character
                    )
                st.markdown(response)

            st.session_state.messages.append({"role": "assistant", "content": response})

            # Auto-save conversation periodically
            if len(st.session_state.messages) % 6 == 0:
                self.save_current_conversation()

    def render_conversations_history(self):
        """Render conversation history page"""
        st.title("ğŸ“š å¯¹è¯å†å²")

        if not st.session_state.selected_character:
            st.info("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªè§’è‰²æŸ¥çœ‹å¯¹è¯å†å²")
            return

        character = st.session_state.selected_character
        conversations = self.db.get_conversations_by_character(character.id)

        if not conversations:
            st.info(f"æš‚æ— ä¸ {character.name} çš„å¯¹è¯è®°å½•")
            return

        st.markdown(f"### {character.avatar_emoji} {character.name} çš„å¯¹è¯è®°å½•")

        for conversation in conversations:
            with st.expander(
                f"ğŸ—‚ï¸ {conversation.title} ({len(conversation.messages)} æ¡æ¶ˆæ¯)"
            ):
                st.markdown(
                    f"**åˆ›å»ºæ—¶é—´:** {conversation.created_at.strftime('%Y-%m-%d %H:%M')}"
                )

                if conversation.messages:
                    st.markdown("**å¯¹è¯å†…å®¹:**")
                    for msg in conversation.messages[-6:]:  # Show last 6 messages
                        role_icon = (
                            "ğŸ‘¤"
                            if msg.role == MessageRole.USER
                            else character.avatar_emoji
                        )

                        # Check if this is an audio message
                        if msg.metadata and "audio" in msg.metadata:
                            audio_info = msg.metadata["audio"]
                            duration_str = audio_manager.format_duration(
                                audio_info.get("duration", 0)
                            )
                            st.markdown(
                                f"{role_icon} **{msg.role.value}:** ğŸ¤ è¯­éŸ³æ¶ˆæ¯ ({duration_str})"
                            )
                            if msg.content and msg.content != "[éŸ³é¢‘æ¶ˆæ¯]":
                                st.markdown(f"   *è½¬å½•:* {msg.content}")
                        else:
                            st.markdown(
                                f"{role_icon} **{msg.role.value}:** {msg.content}"
                            )

                    if len(conversation.messages) > 6:
                        st.markdown(
                            f"*...è¿˜æœ‰ {len(conversation.messages) - 6} æ¡æ¶ˆæ¯*"
                        )

                # Action buttons
                col1, col2 = st.columns(2)
                with col1:
                    if st.button(f"ğŸ”„ åŠ è½½å¯¹è¯", key=f"load_{conversation.id}"):
                        # Load conversation into current session with metadata
                        messages = []
                        for msg in conversation.messages:
                            message_data = {
                                "role": msg.role.value,
                                "content": msg.content,
                            }
                            if msg.metadata:
                                message_data["metadata"] = msg.metadata
                            messages.append(message_data)

                        st.session_state.messages = messages
                        st.session_state.current_conversation_id = conversation.id
                        st.success("å¯¹è¯å·²åŠ è½½!")
                        st.rerun()

                with col2:
                    if st.button(f"ğŸ—‘ï¸ åˆ é™¤", key=f"delete_{conversation.id}"):
                        self.db.delete_conversation(conversation.id)
                        st.success("å¯¹è¯å·²åˆ é™¤!")
                        st.rerun()

    def run(self):
        st.set_page_config(
            page_title=os.getenv("APP_TITLE", "AIè§’è‰²æ‰®æ¼”èŠå¤©ç½‘ç«™"),
            page_icon="ğŸ­",
            layout="wide",
        )

        # Main navigation
        tab1, tab2 = st.tabs(["ğŸ’¬ è§’è‰²å¯¹è¯", "ğŸ“š å¯¹è¯å†å²"])

        # Render sidebar for both tabs
        self.render_sidebar()

        with tab1:
            self.render_chat()

        with tab2:
            self.render_conversations_history()


if __name__ == "__main__":
    app = AIRolePlayApp()
    app.run()
