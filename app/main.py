import sys
import os
from pathlib import Path

# Add project root to path if not already there
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

import streamlit as st
from openai import OpenAI
from typing import List, Dict, Any
from dotenv import load_dotenv
from datetime import datetime

# Import our enhanced database and models
from app.database import DatabaseManager
from app.models import Character, MessageRole

# Import audio processing utilities
from services.audio_utils import audio_manager, AudioUI, TTSPlaybackUI

# Import speech-to-text service
from services.stt_service import stt_service, STTResult

# Import text-to-speech service
from services.tts_service import tts_manager

# Import skill system
from skills.core.manager import SkillManager
from skills.built_in.skill_registry_setup import initialize_skill_system

try:
    from audiorecorder import audiorecorder

    AUDIO_RECORDER_AVAILABLE = True
except ImportError:
    AUDIO_RECORDER_AVAILABLE = False

load_dotenv()


class AIRolePlayApp:
    def __init__(self):
        self.db = DatabaseManager()
        self.ensure_characters_exist()  # Ensure characters exist for cloud deployment
        self.init_openai()
        self.init_session_state()
        self.init_audio_cleanup()
        self.init_skill_system()

    def ensure_characters_exist(self):
        """Ensure preset characters exist in database for cloud deployment"""
        try:
            characters = self.db.get_all_characters()
            if not characters:
                print("No characters found, initializing preset characters...")
                from config.preset_characters import populate_preset_characters
                characters = populate_preset_characters(self.db)
                print(f"Initialized {len(characters)} preset characters")
        except Exception as e:
            print(f"Warning: Could not initialize characters: {e}")

    def init_openai(self):
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            st.error("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®OPENAI_API_KEY")
            st.stop()
        self.client = OpenAI(api_key=api_key)

    def init_session_state(self):
        if "messages" not in st.session_state:
            st.session_state.messages = []
        if "selected_character" not in st.session_state:
            st.session_state.selected_character = None
        if "current_conversation_id" not in st.session_state:
            st.session_state.current_conversation_id = None
        # STT-related session state
        if "stt_enabled" not in st.session_state:
            st.session_state.stt_enabled = True
        if "stt_language" not in st.session_state:
            st.session_state.stt_language = "auto"
        # TTS-related session state
        if "tts_enabled" not in st.session_state:
            st.session_state.tts_enabled = True
        if "tts_auto_play" not in st.session_state:
            st.session_state.tts_auto_play = False
        if "tts_model" not in st.session_state:
            st.session_state.tts_model = "tts-1-hd"
        if "tts_format" not in st.session_state:
            st.session_state.tts_format = "mp3"
        # Text input management
        if "text_input_value" not in st.session_state:
            st.session_state.text_input_value = ""
        if "input_key" not in st.session_state:
            st.session_state.input_key = 0
        # AI response generation state
        if "generating_response" not in st.session_state:
            st.session_state.generating_response = False

        # Clean up old processed audio IDs to prevent memory buildup
        self._cleanup_processed_audio_ids()

    def init_skill_system(self):
        """åˆå§‹åŒ–æŠ€èƒ½ç³»ç»Ÿ"""
        try:
            # åˆå§‹åŒ–æŠ€èƒ½æ³¨å†Œè¡¨å’Œé…ç½®
            self.character_skill_configs = initialize_skill_system()

            # åˆ›å»ºæŠ€èƒ½ç®¡ç†å™¨
            self.skill_manager = SkillManager()

            # åˆå§‹åŒ–æŠ€èƒ½ç³»ç»Ÿï¼ˆå¼‚æ­¥æ–¹æ³•éœ€è¦åœ¨è¿è¡Œæ—¶è°ƒç”¨ï¼‰
            # è¿™é‡Œåªæ˜¯åˆ›å»ºå®ä¾‹ï¼Œå…·ä½“åˆå§‹åŒ–åœ¨ç¬¬ä¸€æ¬¡ä½¿ç”¨æ—¶è¿›è¡Œ

            # åŠ è½½è§’è‰²æŠ€èƒ½é…ç½®åˆ°ç®¡ç†å™¨
            for character_id, configs in self.character_skill_configs.items():
                self.skill_manager.load_character_skill_configs(character_id, configs)

            st.session_state.skill_system_ready = True
            print("âœ… æŠ€èƒ½ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            print(f"âŒ æŠ€èƒ½ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            st.session_state.skill_system_ready = False
            # å¦‚æœæŠ€èƒ½ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œåº”ç”¨ä»å¯æ­£å¸¸è¿è¡Œï¼Œåªæ˜¯ä¸ä½¿ç”¨æŠ€èƒ½å¢å¼º

    def _cleanup_processed_audio_ids(self):
        """Clean up old processed audio IDs to prevent session state buildup"""
        try:
            # Find all processed_audio_ keys
            audio_keys = [
                key
                for key in st.session_state.keys()
                if key.startswith("processed_audio_")
            ]

            # Keep only the most recent 50 processed audio IDs to prevent memory buildup
            if len(audio_keys) > 50:
                # Sort by key to get oldest first (this is a simple approach)
                audio_keys.sort()
                keys_to_remove = audio_keys[:-50]  # Keep only last 50

                for key in keys_to_remove:
                    del st.session_state[key]
        except Exception:
            # Silently handle cleanup errors
            pass

    def init_audio_cleanup(self):
        """Initialize audio file cleanup on app start"""
        try:
            # Clean up old audio files (older than 24 hours)
            audio_manager.cleanup_old_files(max_age_hours=24)
        except Exception:
            # Silently handle cleanup errors
            pass

    def get_character_prompt(self, character: Character) -> str:
        """Generate system prompt from character template"""
        # Use the character's prompt_template directly
        return character.prompt_template

    async def generate_response_with_skills(
        self, user_input: str, character: Character, messages: List[Dict],
        conversation_id: int = None, message_id: int = None
    ) -> str:
        """ä½¿ç”¨æŠ€èƒ½ç³»ç»Ÿç”Ÿæˆå¢å¼ºçš„å“åº”"""
        import asyncio

        if not getattr(st.session_state, 'skill_system_ready', False):
            # æŠ€èƒ½ç³»ç»Ÿæœªå°±ç»ªï¼Œå›é€€åˆ°åŸå§‹æ–¹æ³•
            return self.generate_response(messages, character)

        try:
            # åˆå§‹åŒ–æŠ€èƒ½ç³»ç»Ÿï¼ˆå¦‚æœè¿˜æœªåˆå§‹åŒ–ï¼‰
            if not hasattr(self.skill_manager, '_initialized'):
                await self.skill_manager.initialize()
                self.skill_manager._initialized = True

            # æ„å»ºè§’è‰²ä¿¡æ¯
            character_info = {
                "id": character.id,
                "name": character.name,
                "title": character.title,
                "personality": character.personality,
                "skills": character.skills
            }

            # æ„å»ºå¯¹è¯å†å²
            conversation_history = []
            for msg in messages[-10:]:  # æœ€è¿‘10æ¡æ¶ˆæ¯ä½œä¸ºå†å²
                conversation_history.append({
                    "role": msg["role"],
                    "content": msg["content"],
                    "timestamp": datetime.now().isoformat()
                })

            # ä½¿ç”¨æŠ€èƒ½ç³»ç»Ÿå¤„ç†ç”¨æˆ·è¾“å…¥
            skill_results = await self.skill_manager.process_user_input(
                user_input=user_input,
                character_id=character.id,
                conversation_id=conversation_id,
                message_id=message_id,
                character_info=character_info,
                conversation_history=conversation_history,
                session_id=st.session_state.get('session_id', 'default'),
                execution_strategy="adaptive"
            )

            # å¦‚æœæœ‰æŠ€èƒ½ç»“æœï¼Œä½¿ç”¨æŠ€èƒ½å¢å¼ºçš„å“åº”
            if skill_results:
                best_result = max(skill_results, key=lambda r: r.confidence_score)
                if best_result.generated_content and best_result.quality_score > 0.6:
                    return best_result.generated_content

            # å¦‚æœæ²¡æœ‰é«˜è´¨é‡çš„æŠ€èƒ½ç»“æœï¼Œå›é€€åˆ°åŸå§‹æ–¹æ³•
            return self.generate_response(messages, character)

        except Exception as e:
            print(f"æŠ€èƒ½ç³»ç»Ÿå“åº”ç”Ÿæˆå¤±è´¥: {e}")
            # å‘ç”Ÿé”™è¯¯æ—¶å›é€€åˆ°åŸå§‹æ–¹æ³•
            return self.generate_response(messages, character)

    def generate_streaming_response(
        self, messages: List[Dict], character: Character, placeholder
    ) -> str:
        """Generate streaming response with live display in chat"""
        import time
        import asyncio

        # è·å–æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯
        user_input = ""
        if messages and messages[-1]["role"] == "user":
            user_input = messages[-1]["content"]

        # å°è¯•ä½¿ç”¨æŠ€èƒ½ç³»ç»Ÿ
        if getattr(st.session_state, 'skill_system_ready', False) and user_input:
            try:
                # æ˜¾ç¤ºæŠ€èƒ½å¤„ç†çŠ¶æ€
                placeholder.markdown("ğŸ¤” æ­£åœ¨åˆ†æå¹¶è°ƒç”¨ç›¸å…³æŠ€èƒ½...")

                # è¿è¡Œå¼‚æ­¥æŠ€èƒ½å¤„ç†
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

                try:
                    enhanced_response = loop.run_until_complete(
                        self.generate_response_with_skills(
                            user_input, character, messages,
                            st.session_state.get('current_conversation_id'),
                            None  # message_id æš‚æ—¶ä¸ºç©ºï¼Œå¯ä»¥åç»­ä»æ•°æ®åº“è·å–
                        )
                    )

                    if enhanced_response and enhanced_response != self.generate_response(messages, character):
                        # æŠ€èƒ½ç³»ç»Ÿç”Ÿæˆäº†æœ‰æ•ˆå“åº”ï¼Œè¿›è¡Œæµå¼æ˜¾ç¤º
                        placeholder.markdown("âœ¨ æŠ€èƒ½å¢å¼ºå“åº”ç”Ÿæˆä¸­...")
                        time.sleep(0.5)

                        # æ¨¡æ‹Ÿæµå¼è¾“å‡ºæŠ€èƒ½å¢å¼ºçš„å“åº”
                        full_response = ""
                        for i, char in enumerate(enhanced_response):
                            full_response += char
                            if i % 3 == 0:  # æ¯3ä¸ªå­—ç¬¦æ›´æ–°ä¸€æ¬¡ï¼Œæ¨¡æ‹Ÿæ‰“å­—æ•ˆæœ
                                placeholder.markdown(full_response + "â–Š")
                                time.sleep(0.02)

                        placeholder.markdown(full_response)
                        return full_response

                finally:
                    loop.close()

            except Exception as e:
                print(f"æŠ€èƒ½ç³»ç»Ÿæµå¼å“åº”å¤±è´¥: {e}")
                # ç»§ç»­ä½¿ç”¨åŸå§‹æ–¹æ³•

        # åŸå§‹çš„æµå¼å“åº”æ–¹æ³•
        try:
            system_prompt = self.get_character_prompt(character)

            formatted_messages = [{"role": "system", "content": system_prompt}]
            formatted_messages.extend(messages)

            # Small delay to show the thinking state
            time.sleep(0.5)

            response = self.client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
                messages=formatted_messages,
                max_tokens=500,
                temperature=0.8,
                stream=True,
            )

            # Handle streaming response
            full_response = ""
            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    full_response += chunk.choices[0].delta.content
                    placeholder.markdown(full_response + "â–Š")

            # Remove cursor and display final response
            placeholder.markdown(full_response)

            # Auto-generate TTS if auto-play is enabled
            if st.session_state.tts_enabled and st.session_state.tts_auto_play and full_response.strip():
                # Generate TTS audio for auto-play
                tts_audio = tts_manager.generate_character_speech(
                    text=full_response,
                    character=character,
                    show_progress=False,
                    use_cache=True,
                )

                # Store in session state for immediate display
                if tts_audio:
                    tts_key = f"tts_auto_{hash(full_response)}"
                    st.session_state[f"tts_audio_{tts_key}"] = tts_audio
                    # Mark as auto-generated for UI indicators
                    tts_audio["auto_generated"] = True

            return full_response

        except Exception as e:
            error_msg = f"æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›åº”ã€‚é”™è¯¯ï¼š{str(e)}"
            placeholder.markdown(error_msg)
            return error_msg

    def generate_response(self, messages: List[Dict], character: Character) -> str:
        try:
            system_prompt = self.get_character_prompt(character)

            formatted_messages = [{"role": "system", "content": system_prompt}]
            formatted_messages.extend(messages)

            response = self.client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
                messages=formatted_messages,
                max_tokens=500,
                temperature=0.8,
            )

            return response.choices[0].message.content

        except Exception as e:
            return f"æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›åº”ã€‚é”™è¯¯ï¼š{str(e)}"

    def render_character_skills(self, character: Character):
        """æ¸²æŸ“è§’è‰²çš„æ™ºèƒ½æŠ€èƒ½"""
        st.markdown("**ğŸ¤– æ™ºèƒ½æŠ€èƒ½:**")

        # è·å–è§’è‰²çš„æŠ€èƒ½é…ç½®
        character_skills = self._get_character_skill_configs(character.id)

        if not character_skills:
            st.markdown("*æš‚æœªé…ç½®æ™ºèƒ½æŠ€èƒ½*")
            return

        # æŒ‰æƒé‡æ’åºæŠ€èƒ½
        sorted_skills = sorted(character_skills.items(), key=lambda x: x[1].weight, reverse=True)

        # å®šä¹‰æŠ€èƒ½å›¾æ ‡æ˜ å°„
        skill_icons = {
            "deep_questioning": "ğŸ¤”",
            "storytelling": "ğŸ“–",
            "emotional_support": "ğŸ’",
            "analysis": "ğŸ”"
        }

        # å®šä¹‰æŠ€èƒ½æ˜¾ç¤ºåç§°å’Œæè¿°
        skill_info = {
            "deep_questioning": {
                "name": "æ·±åº¦æé—®",
                "description": "é€šè¿‡è‹æ ¼æ‹‰åº•å¼æé—®å¼•å¯¼æ·±å…¥æ€è€ƒï¼Œè§¦å‘è¯ï¼šä¸ºä»€ä¹ˆã€å¦‚ä½•ã€åŸç†ã€æœ¬è´¨"
            },
            "storytelling": {
                "name": "æ•…äº‹è®²è¿°",
                "description": "è®²è¿°å¼•äººå…¥èƒœçš„æ•…äº‹å’Œç»å†ï¼Œè§¦å‘è¯ï¼šæ•…äº‹ã€ç»å†ã€å†’é™©ã€åˆ†äº«ã€è®²è¿°"
            },
            "emotional_support": {
                "name": "æƒ…æ„Ÿæ”¯æŒ",
                "description": "æä¾›æƒ…æ„Ÿæ”¯æŒå’Œå…±æƒ…ç†è§£ï¼Œè§¦å‘è¯ï¼šéš¾è¿‡ã€æ‹…å¿ƒã€ç„¦è™‘ã€å®³æ€•ã€å­¤ç‹¬"
            },
            "analysis": {
                "name": "æ·±åº¦åˆ†æ",
                "description": "å¯¹å¤æ‚é—®é¢˜è¿›è¡Œé€»è¾‘åˆ†æï¼Œè§¦å‘è¯ï¼šåˆ†æã€æ¯”è¾ƒã€è¯„ä»·ã€ä¼˜ç¼ºç‚¹ã€åŸå› "
            }
        }

        # æ¸²æŸ“æ¯ä¸ªæŠ€èƒ½
        for skill_name, skill_config in sorted_skills:
            icon = skill_icons.get(skill_name, "âš¡")
            skill_data = skill_info.get(skill_name, {"name": skill_name, "description": "æ™ºèƒ½æŠ€èƒ½"})
            display_name = skill_data["name"]
            description = skill_data["description"]
            stars = self._get_skill_stars(skill_config.weight)

            # åˆ›å»ºå¸¦æç¤ºçš„æŠ€èƒ½å±•ç¤º
            with st.container():
                st.markdown(f"{icon} {display_name} {stars}", help=description)

    def _get_character_skill_configs(self, character_id: int):
        """è·å–è§’è‰²çš„æŠ€èƒ½é…ç½®"""
        if hasattr(self, 'character_skill_configs') and character_id in self.character_skill_configs:
            return self.character_skill_configs[character_id]
        return {}

    def _get_skill_stars(self, weight: float) -> str:
        """æ ¹æ®æƒé‡è¿”å›æ˜Ÿçº§æ˜¾ç¤º"""
        if weight >= 1.5:
            return "â­â­â­"
        elif weight >= 1.0:
            return "â­â­"
        else:
            return "â­"

    def render_skill_system_status(self, character: Character):
        """æ¸²æŸ“æŠ€èƒ½ç³»ç»ŸçŠ¶æ€"""
        st.markdown("### âš¡ æ™ºèƒ½æŠ€èƒ½ç³»ç»Ÿ")

        # ç³»ç»ŸçŠ¶æ€æŒ‡ç¤ºå™¨
        skill_system_ready = getattr(st.session_state, 'skill_system_ready', False)

        if skill_system_ready:
            st.success("ğŸŸ¢ æŠ€èƒ½ç³»ç»Ÿå·²å¯ç”¨")

            # æ˜¾ç¤ºå¯ç”¨æŠ€èƒ½
            if hasattr(self, 'skill_manager'):
                try:
                    # è·å–è§’è‰²çš„æŠ€èƒ½å»ºè®®
                    suggestions = self.skill_manager.get_skill_suggestions(
                        user_input="ç¤ºä¾‹è¾“å…¥",
                        character_id=character.id,
                        max_suggestions=3
                    )

                    if suggestions:
                        st.markdown("**å¯ç”¨æ™ºèƒ½æŠ€èƒ½:**")
                        for suggestion in suggestions:
                            confidence_icon = "ğŸ”¥" if suggestion["confidence"] > 0.8 else "â­" if suggestion["confidence"] > 0.6 else "ğŸ’¡"
                            st.markdown(f"{confidence_icon} {suggestion['display_name']}")

                    # ç³»ç»Ÿç»Ÿè®¡
                    with st.expander("ğŸ“Š ç³»ç»ŸçŠ¶æ€", expanded=False):
                        status = self.skill_manager.get_system_status()
                        st.write(f"- å·²æ³¨å†ŒæŠ€èƒ½: {status['registry']['total_skills']}")
                        st.write(f"- å¯ç”¨æŠ€èƒ½: {status['registry']['enabled_skills']}")
                        st.write(f"- æ´»è·ƒæ‰§è¡Œ: {status['executor']['active_executions']}")

                except Exception as e:
                    st.warning(f"æŠ€èƒ½çŠ¶æ€è·å–å¤±è´¥: {str(e)[:50]}...")

        else:
            st.warning("ğŸŸ¡ æŠ€èƒ½ç³»ç»Ÿæœªå°±ç»ª")
            if st.button("ğŸ”„ é‡æ–°åˆå§‹åŒ–", help="é‡æ–°åˆå§‹åŒ–æŠ€èƒ½ç³»ç»Ÿ"):
                try:
                    self.init_skill_system()
                    st.rerun()
                except Exception as e:
                    st.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")

    def render_sidebar(self):
        with st.sidebar:
            st.title("ğŸ­ è§’è‰²é€‰æ‹©")

            characters = self.db.get_all_characters()

            if not characters:
                st.warning(
                    "æ²¡æœ‰æ‰¾åˆ°è§’è‰²ã€‚è¯·è¿è¡Œ `python init_database.py` åˆå§‹åŒ–æ•°æ®åº“ã€‚"
                )
                return

            character_options = {
                f"{char.avatar_emoji} {char.name}": char for char in characters
            }

            selected_display_name = st.selectbox(
                "é€‰æ‹©ä¸€ä¸ªè§’è‰²å¼€å§‹å¯¹è¯", list(character_options.keys()), index=0
            )

            if selected_display_name:
                selected_character = character_options[selected_display_name]

                # Check if character changed
                if (
                    st.session_state.selected_character is None
                    or st.session_state.selected_character.id != selected_character.id
                ):
                    st.session_state.selected_character = selected_character
                    st.session_state.messages = []
                    st.session_state.current_conversation_id = None

                st.markdown("---")

                # Display character info
                st.markdown(
                    f"### {selected_character.avatar_emoji} {selected_character.name}"
                )
                st.markdown(f"**{selected_character.title}**")

                # Display AI skills
                self.render_character_skills(selected_character)

                # Display personality traits (collapsed)
                with st.expander("æ€§æ ¼ç‰¹å¾", expanded=False):
                    if selected_character.personality:
                        for trait in selected_character.personality:
                            st.markdown(f"â€¢ {trait}")

                st.markdown("---")

                # Skill System Status
                self.render_skill_system_status(selected_character)

                st.markdown("---")

                # STT Settings
                st.markdown("### ğŸ¤ è¯­éŸ³è¯†åˆ«è®¾ç½®")

                # STT enable/disable
                st.session_state.stt_enabled = st.toggle(
                    "å¯ç”¨è¯­éŸ³è¯†åˆ«",
                    value=st.session_state.stt_enabled,
                    help="å¼€å¯åå½•éŸ³å°†è‡ªåŠ¨è½¬æ¢ä¸ºæ–‡å­—",
                )

                if st.session_state.stt_enabled:
                    # Language selection
                    language_options = {
                        "è‡ªåŠ¨æ£€æµ‹": "auto",
                        "ä¸­æ–‡": "zh",
                        "English": "en",
                    }

                    selected_lang = st.selectbox(
                        "è¯†åˆ«è¯­è¨€",
                        options=list(language_options.keys()),
                        index=list(language_options.values()).index(
                            st.session_state.stt_language
                        ),
                    )
                    st.session_state.stt_language = language_options[selected_lang]

                st.markdown("---")

                # TTS Settings
                st.markdown("### ğŸ™ï¸ è¯­éŸ³åˆæˆè®¾ç½®")

                # TTS enable/disable
                st.session_state.tts_enabled = st.toggle(
                    "å¯ç”¨è¯­éŸ³åˆæˆ",
                    value=st.session_state.tts_enabled,
                    help="å¼€å¯åAIå›å¤å°†ç”Ÿæˆè¯­éŸ³",
                )

                if st.session_state.tts_enabled:
                    # Auto-generate speech option
                    st.session_state.tts_auto_play = st.checkbox(
                        "è‡ªåŠ¨ç”Ÿæˆè¯­éŸ³",
                        value=st.session_state.tts_auto_play,
                        help="AIå›å¤åè‡ªåŠ¨ç”Ÿæˆè¯­éŸ³æ–‡ä»¶",
                    )

                    # Advanced TTS settings
                    with st.expander("é«˜çº§è®¾ç½®", expanded=False):
                        st.session_state.tts_model = st.selectbox(
                            "TTSæ¨¡å‹",
                            options=["tts-1-hd", "tts-1"],
                            index=0 if st.session_state.tts_model == "tts-1-hd" else 1,
                            help="tts-1-hd: é«˜è´¨é‡, tts-1: å¿«é€Ÿ",
                        )

                        st.session_state.tts_format = st.selectbox(
                            "éŸ³é¢‘æ ¼å¼",
                            options=["mp3", "opus", "aac"],
                            index=["mp3", "opus", "aac"].index(
                                st.session_state.tts_format
                            ),
                            help="ä¸åŒæ ¼å¼çš„éŸ³è´¨å’Œå¤§å°æœ‰æ‰€å·®å¼‚",
                        )

                        # Voice preview button
                        if st.button("ğŸµ è¯•å¬è§’è‰²å£°éŸ³"):
                            self.play_character_voice_preview(selected_character)

                    # Show cache management
                    TTSPlaybackUI.show_cache_management()

                st.markdown("---")

                # Action buttons
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", type="secondary"):
                        st.session_state.messages = []
                        st.session_state.current_conversation_id = None
                        st.rerun()

                with col2:
                    if st.button("ğŸ’¾ ä¿å­˜å¯¹è¯"):
                        self.save_current_conversation()
                        st.success("å¯¹è¯å·²ä¿å­˜!")

    def save_current_conversation(self):
        """Save current conversation to database"""
        if not st.session_state.selected_character or not st.session_state.messages:
            return

        character = st.session_state.selected_character

        # Create conversation if not exists
        if not st.session_state.current_conversation_id:
            # Generate title from first user message
            title = "æ–°å¯¹è¯"
            if st.session_state.messages:
                first_user_msg = next(
                    (msg for msg in st.session_state.messages if msg["role"] == "user"),
                    None,
                )
                if first_user_msg:
                    title = first_user_msg["content"][:30] + (
                        "..." if len(first_user_msg["content"]) > 30 else ""
                    )

            conversation_id = self.db.create_conversation(character.id, title)
            st.session_state.current_conversation_id = conversation_id

        # Add messages to conversation
        for message in st.session_state.messages:
            # Check if message already exists (basic deduplication)
            metadata = message.get("metadata")
            self.db.add_message(
                conversation_id=st.session_state.current_conversation_id,
                role=message["role"],
                content=message["content"],
                metadata=metadata,
            )

    def render_chat(self):
        if not st.session_state.selected_character:
            st.info("è¯·åœ¨å·¦ä¾§é€‰æ‹©ä¸€ä¸ªè§’è‰²å¼€å§‹å¯¹è¯")
            return

        character = st.session_state.selected_character
        st.title(f"ğŸ’¬ ä¸ {character.avatar_emoji} {character.name} å¯¹è¯")

        # Display character description
        st.markdown(f"*{character.title}*")
        st.markdown("---")

        chat_container = st.container()

        with chat_container:
            for message in st.session_state.messages:
                role = message["role"]
                content = message["content"]
                metadata = message.get("metadata", {})

                if role == "user":
                    with st.chat_message("user"):
                        # Check if this is an audio message
                        if "audio" in metadata:
                            self.render_audio_message(metadata["audio"], content)
                        else:
                            st.markdown(content)
                elif role == "assistant":
                    with st.chat_message("assistant", avatar=character.avatar_emoji):
                        st.markdown(content)

                        # Add TTS player if enabled
                        if st.session_state.tts_enabled:
                            self.render_tts_for_message(
                                content, character, message.get("message_id")
                            )

            # Check if we need to generate an AI response
            if st.session_state.generating_response:
                with st.chat_message("assistant", avatar=character.avatar_emoji):
                    placeholder = st.empty()

                    # Show thinking status first
                    placeholder.markdown(f"ğŸ¤” {character.name}æ­£åœ¨æ€è€ƒ...")

                    # Generate streaming response (this will replace the thinking message)
                    response = self.generate_streaming_response(
                        st.session_state.messages, character, placeholder
                    )

                    # Add the response to session state and clear the generating flag
                    st.session_state.messages.append(
                        {"role": "assistant", "content": response}
                    )
                    st.session_state.generating_response = False

                    # Auto-save conversation periodically
                    if len(st.session_state.messages) % 6 == 0:
                        self.save_current_conversation()

                    st.rerun()

        # Input section with both text and audio options
        self.render_input_section(character)

    def render_audio_message(self, audio_metadata: Dict[str, Any], content: str):
        """Render an audio message with playback controls and STT results"""
        st.markdown(
            f"ğŸ¤ **è¯­éŸ³æ¶ˆæ¯** ({audio_manager.format_duration(audio_metadata.get('duration', 0))})"
        )

        # Show STT results if available
        stt_result = audio_metadata.get("stt_result")
        if stt_result:
            method = stt_result.get("method", "unknown")
            language = stt_result.get("language", "auto")

            # Show transcription
            st.markdown(f"ğŸ”¤ **è¯†åˆ«ç»“æœ** ({method}, {language}):")

            if content and content != "[éŸ³é¢‘æ¶ˆæ¯]":
                st.markdown(f"*{content}*")
            else:
                st.markdown("*æ— æ³•è¯†åˆ«éŸ³é¢‘å†…å®¹*")

        elif content and content != "[éŸ³é¢‘æ¶ˆæ¯]":
            st.markdown(f"*è½¬å½•æ–‡æœ¬:* {content}")

        # Audio playback
        file_path = audio_metadata.get("file_path")
        if file_path and os.path.exists(file_path):
            with open(file_path, "rb") as audio_file:
                st.audio(audio_file.read(), format="audio/wav")

    def render_input_section(self, character: Character):
        """Render input section with text and audio options"""
        # Create text input and send button layout
        col_input, col_send = st.columns([4, 1])

        with col_input:
            # Text input with current value from session state
            text_value = st.text_input(
                "è¾“å…¥ä½ çš„æ¶ˆæ¯...",
                value=st.session_state.text_input_value,
                key=f"message_input_{st.session_state.input_key}",
                placeholder="è¾“å…¥æ–‡å­—æˆ–ä½¿ç”¨è¯­éŸ³å½•åˆ¶...",
                label_visibility="collapsed",
            )
            # Update session state when text changes
            if text_value != st.session_state.text_input_value:
                st.session_state.text_input_value = text_value

        with col_send:
            # Send button
            send_clicked = st.button("å‘é€", type="primary", use_container_width=True)

        # Audio recording section (simplified)
        if AUDIO_RECORDER_AVAILABLE and st.session_state.stt_enabled:
            st.markdown("### ğŸ¤ è¯­éŸ³å½•åˆ¶")

            # Check dependencies and show warnings
            dependencies_ok = AudioUI.show_dependencies_warning()

            if not dependencies_ok:
                st.info("è¯­éŸ³åŠŸèƒ½æš‚ä¸å¯ç”¨ï¼Œè¯·ä½¿ç”¨æ–‡æœ¬è¾“å…¥")
            else:
                # Check HTTPS requirement
                if not self._check_https_context():
                    AudioUI.show_error_message("https_required")
                    st.info("è¯·ä½¿ç”¨æ–‡æœ¬è¾“å…¥")
                else:
                    try:
                        audio = audiorecorder("ç‚¹å‡»å½•åˆ¶", "ç‚¹å‡»åœæ­¢")

                        if audio and len(audio) > 0:
                            # Create a unique identifier for this audio segment
                            audio_id = hash(audio.export().read())

                            # Check if this audio has already been processed
                            if f"processed_audio_{audio_id}" not in st.session_state:
                                # Validate audio
                                is_valid, error_msg = audio_manager.validate_audio(
                                    audio
                                )

                                if is_valid:
                                    # Mark this audio as being processed to prevent reprocessing
                                    st.session_state[f"processed_audio_{audio_id}"] = (
                                        True
                                    )

                                    # Show audio info
                                    duration = len(audio) / 1000.0
                                    st.info(
                                        f"â±ï¸ å½•åˆ¶æ—¶é•¿: {audio_manager.format_duration(duration)} - æ­£åœ¨è‡ªåŠ¨è½¬æ¢ä¸ºæ–‡å­—..."
                                    )

                                    # Automatically convert audio to text and add to input
                                    self.auto_convert_audio_to_text(audio, character)
                                    st.rerun()
                                else:
                                    st.error(f"éŸ³é¢‘éªŒè¯å¤±è´¥: {error_msg}")
                    except Exception as e:
                        AudioUI.show_error_message("recording_failed", str(e))

        elif AUDIO_RECORDER_AVAILABLE and not st.session_state.stt_enabled:
            st.info("ğŸ’¡ åœ¨ä¾§è¾¹æ å¯ç”¨è¯­éŸ³è¯†åˆ«ä»¥ä½¿ç”¨è¯­éŸ³å½•åˆ¶åŠŸèƒ½")
        elif not AUDIO_RECORDER_AVAILABLE:
            st.warning(
                "âš ï¸ è¯­éŸ³å½•åˆ¶åŠŸèƒ½ä¸å¯ç”¨ã€‚è¯·å®‰è£…: pip install streamlit-audiorecorder"
            )

        # Process text input when send button clicked or text is entered
        if send_clicked and st.session_state.text_input_value.strip():
            # Add user message to session
            message_data = {
                "role": "user",
                "content": st.session_state.text_input_value.strip(),
            }
            st.session_state.messages.append(message_data)

            # Set flag to generate AI response
            if character:
                st.session_state.generating_response = True

            # Clear the input field and force refresh by changing key
            st.session_state.text_input_value = ""
            st.session_state.input_key += 1
            st.rerun()

    def _check_https_context(self) -> bool:
        """Check if the app is running in HTTPS context for audio recording"""
        try:
            # In Streamlit Cloud or when served over HTTPS, this should work
            # This is a basic check - the actual audio recording will fail gracefully if not HTTPS
            return True  # Let the audiorecorder component handle the HTTPS requirement
        except Exception:
            return False

    def auto_convert_audio_to_text(self, audio_segment, character: Character = None):
        """Automatically convert audio to text and fill input field"""
        with st.spinner("æ­£åœ¨è¯†åˆ«è¯­éŸ³..."):
            # Get character context for better STT accuracy
            prompt = None
            if character:
                prompt = f"è§’è‰²å¯¹è¯: {character.name} - {character.title}"

            # Determine if we should process long audio in chunks
            duration_seconds = len(audio_segment) / 1000.0

            if duration_seconds > 30:  # Long audio
                stt_result = stt_service.process_long_audio(
                    audio_segment, language=st.session_state.stt_language, prompt=prompt
                )
            else:
                stt_result = stt_service.transcribe_audio(
                    audio_segment, language=st.session_state.stt_language, prompt=prompt
                )

        # Handle STT result
        if stt_result.error:
            st.error(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {stt_result.error}")
        elif stt_result.text:
            # Fill the text input with recognized text
            st.session_state.text_input_value = stt_result.text

            # Record statistics
            stt_service.stats_manager.record_request(stt_result, user_edited=False)

            # Show success message
            st.success("è¯­éŸ³è¯†åˆ«æˆåŠŸ!")
        else:
            st.warning("æœªèƒ½è¯†åˆ«å‡ºéŸ³é¢‘å†…å®¹")

    def render_tts_for_message(
        self, text: str, character: Character, message_id: int = None
    ):
        """Render TTS audio player for assistant message"""
        if not text or text.strip() == "":
            return

        # Create unique key for this message's TTS
        tts_key = (
            f"tts_{message_id}_{hash(text)}" if message_id else f"tts_{hash(text)}"
        )

        # Check if TTS audio already exists in session state
        tts_cache_key = f"tts_audio_{tts_key}"
        auto_tts_key = f"tts_audio_tts_auto_{hash(text)}"  # Check for auto-generated TTS

        # Check if auto-generated TTS exists first
        if auto_tts_key in st.session_state:
            # Use auto-generated TTS and move it to the proper key
            tts_audio = st.session_state[auto_tts_key]
            st.session_state[tts_cache_key] = tts_audio
            # Clean up auto key to prevent duplicates
            del st.session_state[auto_tts_key]

        if tts_cache_key not in st.session_state:
            # Check if auto-play is enabled - if so, automatically generate TTS
            if st.session_state.tts_enabled and st.session_state.tts_auto_play:
                with st.spinner("ğŸµ è‡ªåŠ¨ç”Ÿæˆè¯­éŸ³ä¸­..."):
                    tts_audio = tts_manager.generate_character_speech(
                        text=text,
                        character=character,
                        show_progress=False,
                        use_cache=True,
                    )
                    if tts_audio:
                        tts_audio["auto_generated"] = True  # Mark as auto-generated
                        st.session_state[tts_cache_key] = tts_audio
                        st.rerun()
            else:
                # Manual TTS generation button
                col1, col2 = st.columns([1, 3])
                with col1:
                    if st.button("ğŸµ ç”Ÿæˆè¯­éŸ³", key=f"gen_{tts_key}"):
                        with st.spinner("æ­£åœ¨ç”Ÿæˆè¯­éŸ³..."):
                            tts_audio = tts_manager.generate_character_speech(
                                text=text,
                                character=character,
                                show_progress=False,
                                use_cache=True,
                            )
                            if tts_audio:
                                tts_audio["auto_generated"] = False  # Mark as manually generated
                                st.session_state[tts_cache_key] = tts_audio
                                st.rerun()
        else:
            # Display TTS player
            tts_audio = st.session_state[tts_cache_key]
            if tts_audio:
                TTSPlaybackUI.show_tts_player(tts_audio, key_suffix=tts_key)

    def play_character_voice_preview(self, character: Character):
        """Play voice preview for character"""
        with st.spinner("æ­£åœ¨ç”Ÿæˆè¯­éŸ³é¢„è§ˆ..."):
            preview_audio = tts_manager.get_character_voice_preview(character)

        if preview_audio:
            st.success("è¯­éŸ³é¢„è§ˆç”ŸæˆæˆåŠŸï¼")
            TTSPlaybackUI.show_voice_preview_player(
                character.name,
                character.voice_config.voice_id if character.voice_config else "alloy",
                preview_audio,
            )
        else:
            st.error("è¯­éŸ³é¢„è§ˆç”Ÿæˆå¤±è´¥")

    def generate_response_with_tts(
        self, messages: List[Dict], character: Character
    ) -> str:
        """Generate streaming response and optionally create TTS audio"""
        try:
            system_prompt = self.get_character_prompt(character)
            formatted_messages = [{"role": "system", "content": system_prompt}]
            formatted_messages.extend(messages)

            response = self.client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
                messages=formatted_messages,
                max_tokens=500,
                temperature=0.8,
                stream=True,
            )

            # Handle streaming response
            full_response = ""
            placeholder = st.empty()

            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    full_response += chunk.choices[0].delta.content
                    placeholder.markdown(full_response + "â–Š")

            # Remove cursor and display final response
            placeholder.markdown(full_response)

            # Generate TTS if enabled and auto-play is on
            if st.session_state.tts_enabled and st.session_state.tts_auto_play:
                # Generate TTS in background
                tts_audio = tts_manager.generate_character_speech(
                    text=full_response,
                    character=character,
                    show_progress=False,
                    use_cache=True,
                )

                # Store in session state for immediate playback
                if tts_audio:
                    tts_key = f"tts_auto_{hash(full_response)}"
                    st.session_state[f"tts_audio_{tts_key}"] = tts_audio

            return full_response

        except Exception as e:
            return f"æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›åº”ã€‚é”™è¯¯ï¼š{str(e)}"

    def render_conversations_history(self):
        """Render conversation history page"""
        st.title("ğŸ“š å¯¹è¯å†å²")

        if not st.session_state.selected_character:
            st.info("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªè§’è‰²æŸ¥çœ‹å¯¹è¯å†å²")
            return

        character = st.session_state.selected_character
        conversations = self.db.get_conversations_by_character(character.id)

        if not conversations:
            st.info(f"æš‚æ— ä¸ {character.name} çš„å¯¹è¯è®°å½•")
            return

        st.markdown(f"### {character.avatar_emoji} {character.name} çš„å¯¹è¯è®°å½•")

        for conversation in conversations:
            with st.expander(
                f"ğŸ—‚ï¸ {conversation.title} ({len(conversation.messages)} æ¡æ¶ˆæ¯)"
            ):
                st.markdown(
                    f"**åˆ›å»ºæ—¶é—´:** {conversation.created_at.strftime('%Y-%m-%d %H:%M')}"
                )

                if conversation.messages:
                    st.markdown("**å¯¹è¯å†…å®¹:**")
                    for msg in conversation.messages[-6:]:  # Show last 6 messages
                        role_icon = (
                            "ğŸ‘¤"
                            if msg.role == MessageRole.USER
                            else character.avatar_emoji
                        )

                        # Check if this is an audio message
                        if msg.metadata and "audio" in msg.metadata:
                            audio_info = msg.metadata["audio"]
                            duration_str = audio_manager.format_duration(
                                audio_info.get("duration", 0)
                            )

                            # Show STT info if available
                            stt_info = audio_info.get("stt_result")
                            if stt_info:
                                method = stt_info.get("method", "unknown")
                                st.markdown(
                                    f"{role_icon} **{msg.role.value}:** ğŸ¤ è¯­éŸ³æ¶ˆæ¯ ({duration_str}, {method})"
                                )
                            else:
                                st.markdown(
                                    f"{role_icon} **{msg.role.value}:** ğŸ¤ è¯­éŸ³æ¶ˆæ¯ ({duration_str})"
                                )

                            if msg.content and msg.content != "[éŸ³é¢‘æ¶ˆæ¯]":
                                st.markdown(f"   *å†…å®¹:* {msg.content}")
                        else:
                            st.markdown(
                                f"{role_icon} **{msg.role.value}:** {msg.content}"
                            )

                    if len(conversation.messages) > 6:
                        st.markdown(
                            f"*...è¿˜æœ‰ {len(conversation.messages) - 6} æ¡æ¶ˆæ¯*"
                        )

                # Action buttons
                col1, col2 = st.columns(2)
                with col1:
                    if st.button(f"ğŸ”„ åŠ è½½å¯¹è¯", key=f"load_{conversation.id}"):
                        # Load conversation into current session with metadata
                        messages = []
                        for msg in conversation.messages:
                            message_data = {
                                "role": msg.role.value,
                                "content": msg.content,
                            }
                            if msg.metadata:
                                message_data["metadata"] = msg.metadata
                            messages.append(message_data)

                        st.session_state.messages = messages
                        st.session_state.current_conversation_id = conversation.id
                        st.success("å¯¹è¯å·²åŠ è½½!")
                        st.rerun()

                with col2:
                    if st.button(f"ğŸ—‘ï¸ åˆ é™¤", key=f"delete_{conversation.id}"):
                        self.db.delete_conversation(conversation.id)
                        st.success("å¯¹è¯å·²åˆ é™¤!")
                        st.rerun()

    def run(self):
        st.set_page_config(
            page_title=os.getenv("APP_TITLE", "AIè§’è‰²æ‰®æ¼”èŠå¤©ç½‘ç«™"),
            page_icon="ğŸ­",
            layout="wide",
        )

        # Main navigation
        tab1, tab2 = st.tabs(["ğŸ’¬ è§’è‰²å¯¹è¯", "ğŸ“š å¯¹è¯å†å²"])

        # Render sidebar for both tabs
        self.render_sidebar()

        with tab1:
            self.render_chat()

        with tab2:
            self.render_conversations_history()


if __name__ == "__main__":
    app = AIRolePlayApp()
    app.run()
