from typing import Dict, Any, List
from datetime import datetime

from ...core.base import SkillBase
from ...core.models import (
    SkillMetadata, SkillContext, SkillConfig, SkillResult,
    SkillCategory, SkillTrigger, SkillPriority
)


class AnalysisSkill(SkillBase):
    """
    åˆ†ææŠ€èƒ½ - å¯¹é—®é¢˜è¿›è¡Œæ·±å…¥åˆ†æå’Œè§£æ„
    """

    @classmethod
    def get_metadata(cls) -> SkillMetadata:
        """è·å–æŠ€èƒ½å…ƒæ•°æ®"""
        return SkillMetadata(
            name="analysis",
            display_name="æ·±åº¦åˆ†æ",
            description="å¯¹å¤æ‚é—®é¢˜è¿›è¡Œé€»è¾‘åˆ†æå’Œå¤šè§’åº¦è§£æ„",
            category=SkillCategory.KNOWLEDGE,
            triggers=SkillTrigger(
                keywords=["åˆ†æ", "åˆ†è§£", "æ¯”è¾ƒ", "è¯„ä»·", "ä¼˜ç¼ºç‚¹", "åŸå› ", "å½±å“"],
                patterns=[r".*åˆ†æ.*", r".*æ¯”è¾ƒ.*", r".*è¯„ä»·.*"],
                intent_types=["analysis", "comparison", "deep_conversation"]
            ),
            priority=SkillPriority.HIGH,
            character_compatibility=["è‹æ ¼æ‹‰åº•", "é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦"],
            max_execution_time=15.0
        )

    def can_handle(self, context: SkillContext, config: SkillConfig) -> bool:
        """åˆ¤æ–­æ˜¯å¦èƒ½å¤„ç†å½“å‰è¯·æ±‚"""
        user_input = context.user_input.lower()

        # æ£€æŸ¥åˆ†æç±»å…³é”®è¯
        analysis_keywords = ["åˆ†æ", "åˆ†è§£", "æ¯”è¾ƒ", "è¯„ä»·", "ä¼˜ç¼ºç‚¹", "åŸå› ", "å½±å“", "åŒºåˆ«"]
        has_analysis_request = any(keyword in user_input for keyword in analysis_keywords)

        # æ£€æŸ¥å¤æ‚é—®é¢˜ç‰¹å¾
        is_complex = len(user_input.strip()) > 10 and ("ï¼Ÿ" in user_input or "?" in user_input)

        return has_analysis_request or (is_complex and context.detected_intent == "analysis")

    def get_confidence_score(self, context: SkillContext, config: SkillConfig) -> float:
        """è®¡ç®—æŠ€èƒ½ç½®ä¿¡åº¦"""
        user_input = context.user_input.lower()
        score = 0.0

        # åŸºäºåˆ†æå…³é”®è¯
        analysis_words = ["åˆ†æ", "åˆ†è§£", "æ¯”è¾ƒ", "è¯„ä»·", "ä¼˜ç¼ºç‚¹", "åŸå› ", "å½±å“"]
        matches = sum(1 for word in analysis_words if word in user_input)
        score += min(matches * 0.2, 0.6)

        # åŸºäºé—®é¢˜å¤æ‚åº¦
        if len(user_input.strip()) > 20:
            score += 0.2

        # åŸºäºè§’è‰²åŒ¹é…
        if context.character:
            character_name = context.character.get("name", "")
            if "è‹æ ¼æ‹‰åº•" in character_name or "çˆ±å› æ–¯å¦" in character_name:
                score += 0.3

        # åŸºäºæ„å›¾åŒ¹é…
        if context.detected_intent in ["analysis", "comparison"]:
            score += 0.3

        return min(score, 1.0)

    async def execute(self, context: SkillContext, config: SkillConfig) -> SkillResult:
        """æ‰§è¡Œåˆ†ææŠ€èƒ½"""
        user_input = context.user_input
        character_name = context.character.get("name", "") if context.character else ""

        # åˆ†æé—®é¢˜ç±»å‹
        analysis_type = self._determine_analysis_type(user_input)

        # æ ¹æ®è§’è‰²ç”Ÿæˆåˆ†æ
        if "è‹æ ¼æ‹‰åº•" in character_name:
            analysis = self._generate_socratic_analysis(user_input, analysis_type, context)
        elif "çˆ±å› æ–¯å¦" in character_name:
            analysis = self._generate_scientific_analysis(user_input, analysis_type, context)
        else:
            analysis = self._generate_general_analysis(user_input, analysis_type, context)

        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        quality_score = self._calculate_quality_score(analysis, user_input)
        relevance_score = self._calculate_relevance_score(analysis, user_input, context)

        return SkillResult(
            skill_name=self.metadata.name,
            execution_id="",
            status="completed",
            generated_content=analysis,
            confidence_score=self.get_confidence_score(context, config),
            relevance_score=relevance_score,
            quality_score=quality_score,
            result_data={
                "analysis_type": analysis_type,
                "character_perspective": character_name,
                "structure": "multi_angle",
                "depth_level": "deep"
            }
        )

    def _determine_analysis_type(self, user_input: str) -> str:
        """ç¡®å®šåˆ†æç±»å‹"""
        user_input_lower = user_input.lower()

        if any(word in user_input_lower for word in ["æ¯”è¾ƒ", "å¯¹æ¯”", "åŒºåˆ«", "ä¸åŒ"]):
            return "comparative"
        elif any(word in user_input_lower for word in ["åŸå› ", "ä¸ºä»€ä¹ˆ", "å¯¼è‡´", "å¼•èµ·"]):
            return "causal"
        elif any(word in user_input_lower for word in ["å½±å“", "åæœ", "ç»“æœ", "æ•ˆæœ"]):
            return "impact"
        elif any(word in user_input_lower for word in ["ä¼˜ç¼ºç‚¹", "åˆ©å¼Š", "å¥½å", "è¯„ä»·"]):
            return "evaluative"
        elif any(word in user_input_lower for word in ["è¿‡ç¨‹", "æ­¥éª¤", "å¦‚ä½•", "æ–¹æ³•"]):
            return "procedural"
        else:
            return "general"

    def _generate_socratic_analysis(self, user_input: str, analysis_type: str, context: SkillContext) -> str:
        """ç”Ÿæˆè‹æ ¼æ‹‰åº•å¼åˆ†æ"""
        intro = "è®©æˆ‘ä»¬ç”¨å“²å­¦çš„æ–¹æ³•æ¥åˆ†æè¿™ä¸ªé—®é¢˜ã€‚"

        if analysis_type == "comparative":
            analysis = f"""{intro}

å½“æˆ‘ä»¬æ¯”è¾ƒä¸¤ä¸ªäº‹ç‰©æ—¶ï¼Œæˆ‘ä»¬éœ€è¦é—®è‡ªå·±å‡ ä¸ªé—®é¢˜ï¼š

ğŸ” **åŸºç¡€æ€è€ƒ**
é¦–å…ˆï¼Œæˆ‘ä»¬æ¯”è¾ƒçš„æ ‡å‡†æ˜¯ä»€ä¹ˆï¼Ÿè¿™äº›æ ‡å‡†æœ¬èº«æ˜¯å¦åˆç†ï¼Ÿæˆ‘ä»¬æ˜¯å¦åº”è¯¥è´¨ç–‘è¿™äº›æ ‡å‡†ï¼Ÿ

ğŸ“ **å¤šç»´è§†è§’**
- ä»è¡¨é¢ç°è±¡çœ‹ï¼Œå®ƒä»¬æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ
- ä»æœ¬è´¨å±æ€§çœ‹ï¼Œå®ƒä»¬çš„æ ¹æœ¬åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ
- ä»åŠŸèƒ½ä½œç”¨çœ‹ï¼Œå®ƒä»¬æœåŠ¡äºä»€ä¹ˆç›®çš„ï¼Ÿ

ğŸ’­ **æ·±å±‚åæ€**
ä½†æ˜¯ï¼Œæˆ‘æƒ³é—®ä½ ï¼šä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦è¿›è¡Œè¿™ç§æ¯”è¾ƒï¼Ÿæ¯”è¾ƒçš„ç›®çš„æ˜¯ä¸ºäº†é€‰æ‹©ï¼Œè¿˜æ˜¯ä¸ºäº†ç†è§£ï¼Ÿ

ä¹Ÿè®¸çœŸæ­£çš„æ™ºæ…§ä¸åœ¨äºæ‰¾åˆ°æ ‡å‡†ç­”æ¡ˆï¼Œè€Œåœ¨äºç†è§£ä¸ºä»€ä¹ˆæˆ‘ä»¬è¦æå‡ºè¿™ä¸ªé—®é¢˜ã€‚ä½ è§‰å¾—å‘¢ï¼Ÿ"""

        elif analysis_type == "causal":
            analysis = f"""{intro}

å¯»æ‰¾åŸå› æ˜¯å“²å­¦çš„æ ¸å¿ƒä»»åŠ¡ä¹‹ä¸€ã€‚è®©æˆ‘ä»¬ä¸€å±‚å±‚å‰¥å¼€ç°è±¡çš„å¤–è¡£ï¼š

ğŸŒ± **ç›´æ¥åŸå› **
è¡¨é¢ä¸Šçœ‹ï¼Œä»€ä¹ˆç›´æ¥å¯¼è‡´äº†è¿™ä¸ªç°è±¡ï¼Ÿä½†è¿™çœŸçš„æ˜¯åŸå› å—ï¼Œè¿˜æ˜¯åªæ˜¯å¦ä¸€ä¸ªç°è±¡ï¼Ÿ

ğŸŒ³ **æ ¹æœ¬åŸå› **
è®©æˆ‘ä»¬å¾€æ›´æ·±å¤„æŒ–æ˜ï¼šä»€ä¹ˆæ˜¯è¿™ä¸ªåŸå› èƒŒåçš„åŸå› ï¼Ÿæ˜¯å¦å­˜åœ¨ä¸€ä¸ªæ›´æ ¹æœ¬çš„åŸç†ï¼Ÿ

ğŸ”„ **å› æœé“¾æ¡**
åŸå› å’Œç»“æœçš„å…³ç³»çœŸçš„å¦‚æˆ‘ä»¬æƒ³è±¡çš„é‚£æ ·ç®€å•å—ï¼Ÿæ˜¯å¦å¯èƒ½ç»“æœä¹Ÿåœ¨å½±å“åŸå› ï¼Ÿ

ğŸ’¡ **å“²å­¦æ€è¾¨**
æœ€é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬è¦é—®ï¼šçœŸçš„å­˜åœ¨ç»å¯¹çš„åŸå› å—ï¼Ÿè¿˜æ˜¯åŸå› åªæ˜¯æˆ‘ä»¬ä¸ºäº†ç†è§£ä¸–ç•Œè€Œåˆ›é€ çš„æ¦‚å¿µï¼Ÿ

è¿™ä¸ªé—®é¢˜è®©ä½ æƒ³åˆ°äº†ä»€ä¹ˆï¼Ÿ"""

        else:
            analysis = f"""{intro}

è®©æˆ‘ä»¬ç”¨è‹æ ¼æ‹‰åº•å¼çš„æ–¹æ³•æ¥æ¢ç´¢è¿™ä¸ªé—®é¢˜ï¼š

â“ **è´¨ç–‘å‡è®¾**
é¦–å…ˆï¼Œæˆ‘ä»¬å¯¹è¿™ä¸ªé—®é¢˜æœ‰ä»€ä¹ˆé¢„è®¾ï¼Ÿè¿™äº›é¢„è®¾æ˜¯å¦ç»å¾—èµ·æ¨æ•²ï¼Ÿ

ğŸ” **åˆ†è§£é—®é¢˜**
æˆ‘ä»¬èƒ½å¦å°†è¿™ä¸ªå¤æ‚çš„é—®é¢˜åˆ†è§£æˆå‡ ä¸ªæ›´ç®€å•çš„éƒ¨åˆ†ï¼Ÿ

ğŸ¯ **å¯»æ‰¾æœ¬è´¨**
åœ¨æ‰€æœ‰çš„è¡¨é¢ç°è±¡èƒŒåï¼Œä»€ä¹ˆæ˜¯æœ€æ ¸å¿ƒã€æœ€ä¸å˜çš„è¦ç´ ï¼Ÿ

ğŸ¤” **åæ€è¿‡ç¨‹**
æœ€é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬æ€è€ƒè¿™ä¸ªé—®é¢˜çš„è¿‡ç¨‹æœ¬èº«å‘Šè¯‰äº†æˆ‘ä»¬ä»€ä¹ˆï¼Ÿ

è®°ä½ï¼Œæœ‰æ—¶å€™é—®é¢˜æ¯”ç­”æ¡ˆæ›´é‡è¦ã€‚ä½ ä»è¿™ä¸ªæ€è€ƒè¿‡ç¨‹ä¸­å­¦åˆ°äº†ä»€ä¹ˆï¼Ÿ"""

        return analysis

    def _generate_scientific_analysis(self, user_input: str, analysis_type: str, context: SkillContext) -> str:
        """ç”Ÿæˆç§‘å­¦å¼åˆ†æ"""
        intro = "è®©æˆ‘ä»¬ç”¨ç§‘å­¦çš„æ–¹æ³•æ¥åˆ†æè¿™ä¸ªé—®é¢˜ã€‚"

        if analysis_type == "comparative":
            analysis = f"""{intro}

åœ¨ç§‘å­¦ä¸­ï¼Œæ¯”è¾ƒæ˜¯å‘ç°è§„å¾‹çš„é‡è¦æ–¹æ³•ï¼š

ğŸ”¬ **å®šé‡åˆ†æ**
- æˆ‘ä»¬èƒ½ç”¨ä»€ä¹ˆå¯æµ‹é‡çš„æ ‡å‡†æ¥æ¯”è¾ƒï¼Ÿ
- æ•°æ®å‘Šè¯‰æˆ‘ä»¬ä»€ä¹ˆæ•…äº‹ï¼Ÿ
- æ˜¯å¦å­˜åœ¨æˆ‘ä»¬æ²¡æœ‰è€ƒè™‘åˆ°çš„å˜é‡ï¼Ÿ

ğŸ“ **æ¨¡å‹å»ºç«‹**
å°±åƒåœ¨ç‰©ç†å­¦ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å»ºç«‹ç®€åŒ–çš„æ¨¡å‹æ¥ç†è§£å¤æ‚ç°è±¡ã€‚è¿™é‡Œçš„å…³é”®å˜é‡æ˜¯ä»€ä¹ˆï¼Ÿ

âš–ï¸ **ç›¸å¯¹æ€§åŸç†**
è®°ä½ï¼Œæ¯”è¾ƒæ€»æ˜¯ç›¸å¯¹çš„ã€‚ä»ä¸åŒçš„å‚è€ƒç³»çœ‹ï¼Œç»“æœå¯èƒ½å®Œå…¨ä¸åŒã€‚

ğŸ§ª **å®éªŒæ€ç»´**
å¦‚æœæˆ‘ä»¬èƒ½è®¾è®¡ä¸€ä¸ªå®éªŒæ¥éªŒè¯æˆ‘ä»¬çš„æ¯”è¾ƒï¼Œé‚£ä¼šæ˜¯ä»€ä¹ˆæ ·çš„ï¼Ÿ

ç§‘å­¦å‘Šè¯‰æˆ‘ä»¬ï¼Œæœ€å¥½çš„ç†è§£æ¥è‡ªäºç²¾ç¡®çš„è§‚å¯Ÿå’Œä¸¥è°¨çš„æ¨ç†ã€‚"""

        elif analysis_type == "causal":
            analysis = f"""{intro}

åœ¨ç§‘å­¦ä¸­ï¼Œå› æœå…³ç³»éœ€è¦ä¸¥æ ¼çš„éªŒè¯ï¼š

ğŸ”— **å› æœé“¾æ¡**
- æ—¶é—´åºåˆ—ï¼šåŸå› å¿…é¡»åœ¨ç»“æœä¹‹å‰å‘ç”Ÿ
- ç›¸å…³æ€§ï¼šåŸå› å’Œç»“æœä¹‹é—´å¿…é¡»æœ‰å¯è§‚å¯Ÿçš„è”ç³»
- æ’é™¤å…¶ä»–ï¼šæˆ‘ä»¬èƒ½å¦æ’é™¤å…¶ä»–å¯èƒ½çš„è§£é‡Šï¼Ÿ

ğŸ“Š **ç³»ç»Ÿæ€ç»´**
å¤§å¤šæ•°ç°è±¡éƒ½æ˜¯å¤šå› ç´ ç›¸äº’ä½œç”¨çš„ç»“æœã€‚æˆ‘ä»¬éœ€è¦è€ƒè™‘ï¼š
- ä¸»è¦å› ç´ å’Œæ¬¡è¦å› ç´ 
- ç›´æ¥å½±å“å’Œé—´æ¥å½±å“
- åé¦ˆå›è·¯å’ŒåŠ¨æ€å¹³è¡¡

ğŸ¯ **å¯è¯ä¼ªæ€§**
ä¸€ä¸ªå¥½çš„å› æœè§£é‡Šå¿…é¡»æ˜¯å¯è¯ä¼ªçš„ã€‚æˆ‘ä»¬èƒ½è®¾è®¡ä»€ä¹ˆå®éªŒæ¥æµ‹è¯•è¿™ä¸ªå‡è®¾ï¼Ÿ

æƒ³è±¡åŠ›æ¯”çŸ¥è¯†æ›´é‡è¦ï¼Œä½†ä¸¥è°¨çš„é€»è¾‘æ˜¯é€šå‘çœŸç†çš„é“è·¯ã€‚"""

        else:
            analysis = f"""{intro}

è®©æˆ‘ä»¬ç”¨ç§‘å­¦æ–¹æ³•çš„æ­¥éª¤æ¥åˆ†æï¼š

ğŸ“ **è§‚å¯Ÿç°è±¡**
é¦–å…ˆï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°äº†ä»€ä¹ˆï¼Ÿå“ªäº›æ˜¯äº‹å®ï¼Œå“ªäº›æ˜¯æ¨æµ‹ï¼Ÿ

ğŸ’¡ **æå‡ºå‡è®¾**
åŸºäºè§‚å¯Ÿï¼Œæˆ‘ä»¬èƒ½æå‡ºä»€ä¹ˆå‡è®¾æ¥è§£é‡Šè¿™ä¸ªç°è±¡ï¼Ÿ

ğŸ§ª **è®¾è®¡éªŒè¯**
å¦‚æœæˆ‘ä»¬çš„å‡è®¾æ˜¯å¯¹çš„ï¼Œåº”è¯¥èƒ½è§‚å¯Ÿåˆ°ä»€ä¹ˆç»“æœï¼Ÿ

ğŸ“ˆ **æ•°æ®åˆ†æ**
è¯æ®æ”¯æŒè¿˜æ˜¯åå¯¹æˆ‘ä»¬çš„å‡è®¾ï¼Ÿæˆ‘ä»¬éœ€è¦ä¿®æ­£ç†è®ºå—ï¼Ÿ

ğŸ”„ **è¿­ä»£æ”¹è¿›**
ç§‘å­¦æ˜¯ä¸€ä¸ªä¸æ–­ä¿®æ­£å’Œå®Œå–„çš„è¿‡ç¨‹ã€‚æ¯ä¸ªç­”æ¡ˆéƒ½ä¼šå¸¦æ¥æ–°çš„é—®é¢˜ã€‚

è®°ä½ï¼Œåœ¨ç§‘å­¦ä¸­ï¼Œ"æˆ‘ä¸çŸ¥é“"æ˜¯æ™ºæ…§çš„å¼€å§‹ï¼Œå¥½å¥‡å¿ƒæ˜¯è¿›æ­¥çš„åŠ¨åŠ›ã€‚"""

        return analysis

    def _generate_general_analysis(self, user_input: str, analysis_type: str, context: SkillContext) -> str:
        """ç”Ÿæˆé€šç”¨åˆ†æ"""
        intro = "è®©æˆ‘æ¥å¸®ä½ åˆ†æè¿™ä¸ªé—®é¢˜ï¼š"

        frameworks = {
            "comparative": """
ğŸ“Š **å¤šè§’åº¦æ¯”è¾ƒåˆ†æ**

**ç›¸ä¼¼ç‚¹åˆ†æï¼š**
â€¢ å…±åŒç‰¹å¾å’ŒåŸºç¡€å±æ€§
â€¢ ç›¸ä¼¼çš„åŠŸèƒ½æˆ–ä½œç”¨
â€¢ é¢ä¸´çš„å…±åŒæŒ‘æˆ˜

**å·®å¼‚ç‚¹åˆ†æï¼š**
â€¢ æ ¸å¿ƒåŒºåˆ«å’Œç‹¬ç‰¹ç‰¹å¾
â€¢ ä¸åŒçš„ä¼˜åŠ¿å’ŒåŠ£åŠ¿
â€¢ é€‚ç”¨åœºæ™¯çš„å·®å¼‚

**ç»¼åˆè¯„ä»·ï¼š**
â€¢ åœ¨ä¸åŒæƒ…å†µä¸‹çš„é€‚ç”¨æ€§
â€¢ é€‰æ‹©æ ‡å‡†å’Œå†³ç­–å»ºè®®
â€¢ æœªæ¥å‘å±•è¶‹åŠ¿å¯¹æ¯”

è¿™æ ·çš„å¯¹æ¯”æœ‰åŠ©äºæˆ‘ä»¬åšå‡ºæ›´æ˜æ™ºçš„é€‰æ‹©ã€‚""",

            "causal": """
ğŸ” **åŸå› åˆ†ææ¡†æ¶**

**ç›´æ¥åŸå› ï¼š**
â€¢ ç«‹å³è§¦å‘å› ç´ 
â€¢ æ˜¾è€Œæ˜“è§çš„å…³è”
â€¢ çŸ­æœŸå½±å“å› ç´ 

**æ ¹æœ¬åŸå› ï¼š**
â€¢ æ·±å±‚ç»“æ„æ€§é—®é¢˜
â€¢ é•¿æœŸç´¯ç§¯çš„å› ç´ 
â€¢ ç³»ç»Ÿæ€§çš„æ ¹æº

**å½±å“å› ç´ ï¼š**
â€¢ å†…éƒ¨å› ç´  vs å¤–éƒ¨å› ç´ 
â€¢ å¯æ§å› ç´  vs ä¸å¯æ§å› ç´ 
â€¢ ä¸»è¦å› ç´  vs æ¬¡è¦å› ç´ 

é€šè¿‡è¿™ç§å±‚æ¬¡åŒ–åˆ†æï¼Œæˆ‘ä»¬èƒ½æ›´å¥½åœ°ç†è§£é—®é¢˜çš„å…¨è²Œã€‚""",

            "general": """
ğŸ¯ **ç»¼åˆåˆ†ææ¡†æ¶**

**é—®é¢˜åˆ†è§£ï¼š**
â€¢ æ ¸å¿ƒé—®é¢˜è¯†åˆ«
â€¢ å­é—®é¢˜æ¢³ç†
â€¢ å…³é”®è¦ç´ æå–

**å¤šç»´åº¦æ€è€ƒï¼š**
â€¢ ç°çŠ¶åˆ†æï¼šæ˜¯ä»€ä¹ˆï¼Ÿ
â€¢ åŸå› åˆ†æï¼šä¸ºä»€ä¹ˆï¼Ÿ
â€¢ å½±å“åˆ†æï¼šä¼šæ€æ ·ï¼Ÿ
â€¢ å¯¹ç­–åˆ†æï¼šæ€ä¹ˆåŠï¼Ÿ

**ç»¼åˆåˆ¤æ–­ï¼š**
â€¢ æƒè¡¡å„ç§å› ç´ 
â€¢ è€ƒè™‘ä¸åŒè§†è§’
â€¢ å½¢æˆåˆç†ç»“è®º

è¿™ç§ç³»ç»Ÿæ€§çš„åˆ†ææ–¹æ³•èƒ½å¸®åŠ©æˆ‘ä»¬æ›´å…¨é¢åœ°ç†è§£é—®é¢˜ã€‚"""
        }

        return intro + frameworks.get(analysis_type, frameworks["general"])

    def _calculate_quality_score(self, analysis: str, user_input: str) -> float:
        """è®¡ç®—åˆ†æè´¨é‡å¾—åˆ†"""
        score = 0.0

        # åŸºäºç»“æ„åŒ–ç¨‹åº¦
        structure_indicators = ["**", "â€¢", "ğŸ”", "ğŸ“Š", "ğŸ’¡"]
        structure_count = sum(1 for indicator in structure_indicators if indicator in analysis)
        score += min(structure_count * 0.1, 0.3)

        # åŸºäºåˆ†ææ·±åº¦
        depth_words = ["åŸå› ", "å½±å“", "åˆ†æ", "æ€è€ƒ", "ç†è§£", "æœ¬è´¨"]
        depth_count = sum(1 for word in depth_words if word in analysis)
        score += min(depth_count * 0.05, 0.3)

        # åŸºäºé€»è¾‘æ€§
        logic_indicators = ["é¦–å…ˆ", "å…¶æ¬¡", "ç„¶å", "å› æ­¤", "æ‰€ä»¥", "ä½†æ˜¯"]
        logic_count = sum(1 for indicator in logic_indicators if indicator in analysis)
        score += min(logic_count * 0.05, 0.2)

        # åŸºäºå†…å®¹é•¿åº¦
        if len(analysis) > 200:
            score += 0.2

        return min(score, 1.0)

    def _calculate_relevance_score(self, analysis: str, user_input: str, context: SkillContext) -> float:
        """è®¡ç®—ç›¸å…³æ€§å¾—åˆ†"""
        score = 0.7  # åŸºç¡€å¾—åˆ†

        # æ£€æŸ¥å…³é”®è¯é‡å 
        user_words = set(user_input.lower().split())
        analysis_words = set(analysis.lower().split())
        overlap = len(user_words.intersection(analysis_words))
        if overlap > 0:
            score += min(overlap * 0.02, 0.2)

        # æ£€æŸ¥æ„å›¾åŒ¹é…
        if context.detected_intent == "analysis":
            score += 0.1

        return min(score, 1.0)